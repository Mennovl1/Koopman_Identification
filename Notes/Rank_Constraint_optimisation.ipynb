{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da76509-b38e-462e-8465-200a7a0c555c",
   "metadata": {},
   "source": [
    "## Illustrative example implementing COSMOS ideas on Korda2020 optimisation problem\n",
    "\n",
    "In the paper by Korda2020 we are solving \n",
    "$$ \\min_{\\lambda_i, g_i} \\left\\|\n",
    "  \\begin{bmatrix}\n",
    "      h_i(x^1(0)) & h_i(x^2(0)) & \\cdots \\\\ \n",
    "      h_i(x^1(1)) & h_i(x^2(1)) & \\cdots \\\\ \n",
    "      h_i(x^1(2)) & h_i(x^2(2)) & \\cdots \\\\ \n",
    "      \\vdots & \\vdots & \\ddots %\\\\ h_i(x^1(N)) \\\\ h_i(x^2(0)) \\\\ \\vdots\n",
    "  \\end{bmatrix}- \n",
    "  \\begin{bmatrix}\n",
    "      1 & 1 & 1 & \\cdots \\\\\n",
    "      \\lambda_{1} & \\lambda_{2} & \\lambda_{3} & \\cdots \\\\\n",
    "      \\lambda_{1}^2 & \\lambda_{2}^2 & \\lambda_{3}^2 & \\cdots \\\\\n",
    "      \\vdots & \\vdots & \\vdots & \\ddots\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}% End of phantom section for vertical brace alignment\n",
    "      g_{1} (x^1(0)) & g_{1} (x^2(0)) & \\cdots \\\\ \n",
    "      g_{2} (x^1(0)) & g_{2} (x^2(0)) & \\cdots \\\\\n",
    "      \\vdots & \\vdots & \\ddots\n",
    "  \\end{bmatrix} \\right\\| $$\n",
    "\n",
    "That is, given a matrix $Y$ we seek a decomposition into a product of a Vandermonde matrix $\\Lambda$ and a matrix of initial states $G$, formulated as a least-squares problem $\\| Y - \\Lambda G \\|$. The idea is to turn this problem from a nonconvex problem into a convex problem with rank constraint, and apply the ideas in COSMOS to this work. \n",
    "Defining $D_\\lambda = \\text{diag}(\\lambda_1, \\lambda_2, \\dots)$, and $\\overline \\Lambda$ as the matrix $\\Lambda$, but shifted one place up, we obtain that $\\overline \\Lambda = \\Lambda D_{\\lambda}$. These relationships can be written in terms of a rank constraint, for which we introduce\n",
    "$$ H = \\begin{bmatrix} \\hat M & \\Lambda & \\overline \\Lambda \\\\ \\hat G & I_{N_g} & D_\\lambda \\end{bmatrix}. $$\n",
    "\n",
    "By the Schur decomposition, the rank of the matrix $\\hat M - \\Lambda I_{N_g} \\hat G$ is equivalent to rank of the left $2 \\times 2$ block submatrix of $H$. Similarly, the introduced relationship between $\\Lambda$ and its shifted matrix $\\overline \\Lambda$, gives the latter columns the same rank. Hence we obtain the optimisation problem\n",
    "$$ \\min \\| Y - \\hat M \\| $$\n",
    "subject to $\\text{rank}(H) = N_g$\n",
    "\n",
    "\n",
    "The code below is an iterative method, solving \n",
    "$$ \\text{argmin}_{\\hat M, \\hat G, \\Lambda, \\overline \\Lambda, \\lambda_i} \\| Y - \\hat M \\|_2 + \\rho \\left( \\| H \\|_* - \\text{tr} \\left( U_1^T H V_1 \\right) \\right) $$\n",
    "subject to: \n",
    "\\\\[\\Lambda[0,:] = [1, 1, \\dots] \\\\\n",
    "  \\overline \\Lambda[0:end-1, :] = \\Lambda[1:,:] \\\\\n",
    "  \\Lambda[1,:] = [\\lambda_1, \\lambda_2, \\dots]\\\\]\n",
    "iteratively, using the truncated singular value decomposition for $H = U S V^*$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9534fff1-0099-4af2-87a3-447f87c58eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 completed with error 0.170 and rho=0.01\n",
      "Iteration 2 completed with error 0.012 and rho=0.01\n",
      "Iteration 3 completed with error 0.012 and rho=0.01\n",
      "Iteration 4 completed with error 0.012 and rho=0.01\n",
      "Iteration 5 completed with error 0.011 and rho=0.01\n",
      "Iteration 6 completed with error 0.012 and rho=0.01\n",
      "Iteration 7 completed with error 0.012 and rho=0.01\n",
      "Iteration 8 completed with error 0.012 and rho=0.01\n",
      "Iteration 9 completed with error 0.012 and rho=0.01\n",
      "Iteration 10 completed with error 0.012 and rho=0.01\n",
      "\n",
      "------------------ Finished optimisation procedure with status word: optimal ----------------------------\n",
      "Found eigenvalue sequence                                  [0.74 0.01 0.04]\n",
      "Final nuclear norm of rank-constraint matrix               16.870\n",
      "Least-square norm error ||Y - M||                          0.000\n",
      "Least-square norm error ||Y - L*G||                        10.005\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "def H_Theta(M, Theta, ThetaShift, X, Id, L):\n",
    "    '''Function for constructing the blockmatrix in the rank constraint optimisation problem\n",
    "    Using the input matrices, the following block matrix is constructed:\n",
    "    | M  Theta  ThetaShift |\n",
    "    | X    Id     L        |\n",
    "    '''\n",
    "    return cvx.bmat([[M, Theta, ThetaShift], [X, Id, L]])\n",
    "\n",
    "\n",
    "N = 5                             # Number of rows of measurement data Y, i.e. measurement sequence length\n",
    "N_t = 20                           # Number of columns of measurement data Y, i.e. number of measurement sequences\n",
    "N_g = 3                            # Rank used as rank constraint, and to construct measurement data Y\n",
    "Id = np.eye(N_g)                   # Usefull identity matrix\n",
    "# Total number of optimisation variables = N_t * N_g + N_g\n",
    "\n",
    "# Define Y as decomposed product of a VanderMonde matrix and random initial states.\n",
    "Y = np.vander([0.9, 0.95, 0.8], N, increasing=True).T @ np.random.rand(N_g, N_t) \n",
    "\n",
    "# Initialise U and V as empty matrices\n",
    "U_j = [np.zeros((N + N_g, N_g))]\n",
    "V_j = [np.zeros((N_t + 2 * N_g, N_g))]\n",
    "\n",
    "# Initialise CVX optimisation problem\n",
    "Mhat = cvx.Variable(Y.shape)\n",
    "Ghat = cvx.Variable((N_g, N_t))\n",
    "ThetaHat = cvx.Variable((N,N_g))\n",
    "ThetaHatShift = cvx.Variable((N, N_g))\n",
    "Lhat = cvx.diag(cvx.Variable(N_g, complex=False))      \n",
    "\n",
    "# Constraints: \n",
    "#        Requirement that first row of Theta[0,:] = [ 1, 1, 1, ...]\n",
    "#        Requirement that second row of Theta[1,:] = ThetaShift[0,:]\n",
    "#        Requirement that second row of Theta[1,:] = [lambda_1, lambda_2, ...]\n",
    "cons = [ThetaHat[0,:] == np.ones((N_g,)), ThetaHat[1:,:] == ThetaHatShift[:-1,:], ThetaHat[1,:] == cvx.diag(Lhat)]\n",
    "\n",
    "# Construct rank constraint matrix\n",
    "Fullmatrix = H_Theta(Mhat, ThetaHat, ThetaHatShift, Ghat, Id, Lhat)\n",
    "\n",
    "# Initialise variables that change on optimisation iteration\n",
    "U = cvx.Parameter((N + N_g, N_g), complex=False)\n",
    "V = cvx.Parameter((N_t + 2 * N_g, N_g), complex=False)\n",
    "rho = cvx.Parameter(pos=True)\n",
    "\n",
    "# Define objective function and problem handle\n",
    "obj = cvx.norm(Y - Mhat,2) +  rho * ( cvx.norm(Fullmatrix, \"nuc\") - (cvx.trace(U.T @ Fullmatrix @ V))) \n",
    "prob = cvx.Problem(cvx.Minimize(obj), cons)\n",
    "\n",
    "# Initialise optimisation iteration\n",
    "i = 0\n",
    "eps = 1\n",
    "rho_new = 0.01       # Initial value for rho\n",
    "mu = 1.02            # Growth factor for rho\n",
    "rho_max = 10     # Maximum value for rho\n",
    "prev_value = 1e5\n",
    "\n",
    "# Iterate while error is large and number of iterations is small enough\n",
    "while eps > 1e-4 and i < 10:\n",
    "    rho_new = min(mu * rho_new, rho_max)\n",
    "    \n",
    "    # Set CVX problem parameters\n",
    "    rho.value = rho_new\n",
    "    U.value = U_j[i]\n",
    "    V.value = V_j[i]\n",
    "    \n",
    "    # Solve optimisation problem iteration using cvx\n",
    "    prob.solve(verbose=False)\n",
    "\n",
    "    # Compute SVD of rank-constraint matrix value\n",
    "    Res = Fullmatrix.value # H_Theta_num(M, Theta, ThetaShift, X, Id, L)\n",
    "    U1, s, V1 = np.linalg.svd(Res, full_matrices=True)\n",
    "\n",
    "    U_j.append(U1[:,:N_g])\n",
    "    V_j.append(V1[:N_g,:].T)\n",
    " \n",
    "    # Update error value, and print update\n",
    "    eps = abs((obj.value - prev_value) / obj.value)\n",
    "    prev_value = obj.value\n",
    "    i = i + 1\n",
    "    print(f'Iteration {i} completed with error {obj.value:.3f} and rho={rho_new:.2f}')\n",
    "    \n",
    "# Extract solutions from optimisation procedure\n",
    "M = Mhat.value\n",
    "G = Ghat.value\n",
    "Theta = ThetaHat.value\n",
    "ThetaShift = ThetaHatShift.value\n",
    "L = Lhat.value \n",
    "\n",
    "print()\n",
    "print(f'------------------ Finished optimisation procedure with status word: {prob.status} ----------------------------')\n",
    "print(f'Found eigenvalue sequence                                  {np.array2string(np.diag(L), precision=2)}')\n",
    "# print(Theta)\n",
    "# print(ThetaShift)\n",
    "print(f\"Final nuclear norm of rank-constraint matrix               {np.linalg.norm(Res, 'nuc'):.3f}\")\n",
    "print(f'Least-square norm error ||Y - M||                          {np.linalg.norm(Y - M, 2):.3f}')\n",
    "print(f'Least-square norm error ||Y - L*G||                        {np.linalg.norm(Y - np.vander(np.diag(L), N, increasing=True).T @ G, 2):.3f}') \n",
    "# print(Res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2dbb1c-513a-466f-93a9-129682829fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66403187  0.13799901  0.28469454  0.45899238  0.85754551  0.30486178\n",
      "   0.64588184  0.96166547  0.53413857  0.56828548  0.18937231  0.84072217\n",
      "   0.58207843  0.42535756  0.36603066  0.4377042   0.36263773  0.54922027\n",
      "   0.80179837  0.53304959]\n",
      " [ 0.33882806 -0.04310725  0.08587414  0.20419406  0.46507379  0.14318923\n",
      "   0.34316924  0.6141524   0.30958662  0.29280128  0.09840673  0.4934948\n",
      "   0.32797629  0.2338007   0.17479192  0.21739443  0.18857643  0.25776005\n",
      "   0.40703408  0.27512184]\n",
      " [ 0.24575135 -0.03694164  0.05932875  0.14659792  0.33870634  0.10322796\n",
      "   0.24954926  0.45163256  0.22639764  0.21252895  0.07144897  0.36116321\n",
      "   0.23944169  0.17044832  0.12617741  0.15735222  0.13696963  0.18586996\n",
      "   0.29514658  0.19970403]\n",
      " [ 0.1816857  -0.02751545  0.04375591  0.10832674  0.25045806  0.07629453\n",
      "   0.18451666  0.33411793  0.16744413  0.15713007  0.05282531  0.26712685\n",
      "   0.17707718  0.12604531  0.0932623   0.11631977  0.10126978  0.13737629\n",
      "   0.21820147  0.14764831]\n",
      " [ 0.13444397 -0.02036815  0.03237478  0.08015782  0.185336    0.05645571\n",
      "   0.13653965  0.24724884  0.12390786  0.11627348  0.03908982  0.19767294\n",
      "   0.13103576  0.09327226  0.06901157  0.08607401  0.07493797  0.10165449\n",
      "   0.16146487  0.10925716]]\n",
      "[[1.29079122 1.11319052 0.98389772 1.11817211 1.450676   0.69165896\n",
      "  1.17970528 0.93698728 0.7599925  1.06770269 0.36653932 1.14836952\n",
      "  0.89041671 0.67307344 0.80060772 0.91667322 0.66322751 1.20092141\n",
      "  1.54936986 1.01103701]\n",
      " [1.38983748 1.20008758 1.06035311 1.20432254 1.56181682 0.74478185\n",
      "  1.26964517 1.00749226 0.81786853 1.14984742 0.39445611 1.23573869\n",
      "  0.95850646 0.72496465 0.86219775 0.98674623 0.71431764 1.29390685\n",
      "  1.66867964 1.0886057 ]\n",
      " [1.29026544 1.10932246 0.98130456 1.11690454 1.45050654 0.69125013\n",
      "  1.18052594 0.93984536 0.7607046  1.06679468 0.36685228 1.14964047\n",
      "  0.89061396 0.6722851  0.79991912 0.91687712 0.66252494 1.19856217\n",
      "  1.54780682 1.01065421]\n",
      " [1.18942377 1.02358922 0.90519885 1.02984903 1.33699    0.63728012\n",
      "  1.08796253 0.86543675 0.70095468 0.98350876 0.33808181 1.05928142\n",
      "  0.82081973 0.61980796 0.73750329 0.84511369 0.61082502 1.10532356\n",
      "  1.42703258 0.93165245]\n",
      " [1.09480413 0.94732897 0.83649598 0.94915509 1.22998248 0.58678301\n",
      "  0.99946969 0.79167507 0.6436446  0.90597041 0.31049883 0.97237808\n",
      "  0.75466533 0.57125186 0.67938276 0.77703137 0.56287296 1.02019126\n",
      "  1.31489734 0.85749302]]\n"
     ]
    }
   ],
   "source": [
    "print(np.vander(np.diag(L), N, increasing=True).T @ G)\n",
    "print(Y - np.vander(np.diag(L), N, increasing=True).T @ G)\n",
    "# print(Y - M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
