{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da76509-b38e-462e-8465-200a7a0c555c",
   "metadata": {},
   "source": [
    "## Illustrative example implementing COSMOS ideas on Korda2020 optimisation problem\n",
    "\n",
    "In the paper by Korda2020 we are solving \n",
    "$$ \\min_{\\lambda_i, g_i} \\left\\|\n",
    "  \\begin{bmatrix}\n",
    "      h_i(x^1(0)) & h_i(x^2(0)) & \\cdots \\\\ \n",
    "      h_i(x^1(1)) & h_i(x^2(1)) & \\cdots \\\\ \n",
    "      h_i(x^1(2)) & h_i(x^2(2)) & \\cdots \\\\ \n",
    "      \\vdots & \\vdots & \\ddots %\\\\ h_i(x^1(N)) \\\\ h_i(x^2(0)) \\\\ \\vdots\n",
    "  \\end{bmatrix}- \n",
    "  \\begin{bmatrix}\n",
    "      1 & 1 & 1 & \\cdots \\\\\n",
    "      \\lambda_{1} & \\lambda_{2} & \\lambda_{3} & \\cdots \\\\\n",
    "      \\lambda_{1}^2 & \\lambda_{2}^2 & \\lambda_{3}^2 & \\cdots \\\\\n",
    "      \\vdots & \\vdots & \\vdots & \\ddots\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}% End of phantom section for vertical brace alignment\n",
    "      g_{1} (x^1(0)) & g_{1} (x^2(0)) & \\cdots \\\\ \n",
    "      g_{2} (x^1(0)) & g_{2} (x^2(0)) & \\cdots \\\\\n",
    "      \\vdots & \\vdots & \\ddots\n",
    "  \\end{bmatrix} \\right\\| $$\n",
    "\n",
    "That is, given a matrix $Y$ we seek a decomposition into a product of a Vandermonde matrix $\\Lambda$ and a matrix of initial states $G$, formulated as a least-squares problem $\\| Y - \\Lambda G \\|$. The idea is to turn this problem from a nonconvex problem into a convex problem with rank constraint, and apply the ideas in COSMOS to this work. \n",
    "Defining $D_\\lambda = \\text{diag}(\\lambda_1, \\lambda_2, \\dots)$, and $\\overline \\Lambda$ as the matrix $\\Lambda$, but shifted one place up, we obtain that $\\overline \\Lambda = \\Lambda D_{\\lambda}$. These relationships can be written in terms of a rank constraint, for which we introduce\n",
    "$$ H = \\begin{bmatrix} \\hat M & \\Lambda & \\overline \\Lambda \\\\ \\hat G & I_{N_g} & D_\\lambda \\end{bmatrix}. $$\n",
    "\n",
    "By the Schur decomposition, the rank of the matrix $\\hat M - \\Lambda I_{N_g} \\hat G$ is equivalent to rank of the left $2 \\times 2$ block submatrix of $H$. Similarly, the introduced relationship between $\\Lambda$ and its shifted matrix $\\overline \\Lambda$, gives the latter columns the same rank. Hence we obtain the optimisation problem\n",
    "$$ \\min \\| Y - \\hat M \\| $$\n",
    "subject to $\\text{rank}(H) = N_g$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9534fff1-0099-4af2-87a3-447f87c58eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 completed with error 0.087 and rho=0.01\n",
      "Iteration 2 completed with error 0.013 and rho=0.01\n",
      "Iteration 3 completed with error 0.012 and rho=0.01\n",
      "Iteration 4 completed with error 0.005 and rho=0.01\n",
      "Iteration 5 completed with error 0.003 and rho=0.01\n",
      "Iteration 6 completed with error 0.003 and rho=0.01\n",
      "Iteration 7 completed with error 0.003 and rho=0.01\n",
      "Iteration 8 completed with error 0.003 and rho=0.01\n",
      "Iteration 9 completed with error 0.002 and rho=0.01\n",
      "Iteration 10 completed with error 0.001 and rho=0.01\n",
      "\n",
      "------------------ Finished optimisation procedure with status word: optimal ----------------------------\n",
      "Found eigenvalue sequence                                  [0.16 0.44 0.9 ]\n",
      "Final nuclear norm of rank-constraint matrix               9.002\n",
      "Least-square norm error ||Y - M||                          0.000\n",
      "Least-square norm error ||Y - L*G||                        0.180\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "def H_Theta(M, Theta, ThetaShift, X, Id, L):\n",
    "    '''Function for constructing the blockmatrix in the rank constraint optimisation problem\n",
    "    Using the input matrices, the following block matrix is constructed:\n",
    "    | M  Theta  ThetaShift |\n",
    "    | X    Id     L        |\n",
    "    '''\n",
    "    return cvx.bmat([[M, Theta, ThetaShift], [X, Id, L]])\n",
    "\n",
    "\n",
    "N = 20                             # Number of rows of measurement data Y, i.e. measurement sequence length\n",
    "N_t = 2                           # Number of columns of measurement data Y, i.e. number of measurement sequences\n",
    "N_g = 3                            # Rank used as rank constraint, and to construct measurement data Y\n",
    "Id = np.eye(N_g)                   # Usefull identity matrix\n",
    "# Total number of optimisation variables = N_t * N_g + N_g\n",
    "\n",
    "# Define Y as decomposed product of a VanderMonde matrix and random initial states.\n",
    "Y = np.vander([0.9, 0.95, 0.8], N, increasing=True).T @ np.random.rand(N_g, N_t) \n",
    "\n",
    "# Initialise U and V as empty matrices\n",
    "U_j = [np.zeros((N + N_g, N_g))]\n",
    "V_j = [np.zeros((N_t + 2 * N_g, N_g))]\n",
    "\n",
    "# Initialise CVX optimisation problem\n",
    "Mhat = cvx.Variable(Y.shape)\n",
    "Ghat = cvx.Variable((N_g, N_t))\n",
    "ThetaHat = cvx.Variable((N,N_g))\n",
    "ThetaHatShift = cvx.Variable((N, N_g))\n",
    "Lhat = cvx.diag(cvx.Variable(N_g, complex=False))      \n",
    "\n",
    "# Constraints: \n",
    "#        Requirement that first row of Theta[0,:] = [ 1, 1, 1, ...]\n",
    "#        Requirement that second row of Theta[1,:] = ThetaShift[0,:]\n",
    "#        Requirement that second row of Theta[1,:] = [lambda_1, lambda_2, ...]\n",
    "cons = [ThetaHat[0,:] == np.ones((N_g,)), ThetaHat[1:,:] == ThetaHatShift[:-1,:], ThetaHat[1,:] == cvx.diag(Lhat)]\n",
    "\n",
    "# Construct rank constraint matrix\n",
    "Fullmatrix = H_Theta(Mhat, ThetaHat, ThetaHatShift, Ghat, Id, Lhat)\n",
    "\n",
    "# Initialise variables that change on optimisation iteration\n",
    "U = cvx.Parameter((N + N_g, N_g), complex=False)\n",
    "V = cvx.Parameter((N_t + 2 * N_g, N_g), complex=False)\n",
    "rho = cvx.Parameter(pos=True)\n",
    "\n",
    "# Define objective function and problem handle\n",
    "obj = cvx.norm(Y - Mhat,2) +  rho * ( cvx.norm(Fullmatrix, \"nuc\") - (cvx.trace(U.T @ Fullmatrix @ V))) \n",
    "prob = cvx.Problem(cvx.Minimize(obj), cons)\n",
    "\n",
    "# Initialise optimisation iteration\n",
    "i = 0\n",
    "eps = 1\n",
    "rho_new = 0.01       # Initial value for rho\n",
    "mu = 1.02            # Growth factor for rho\n",
    "rho_max = 10     # Maximum value for rho\n",
    "prev_value = 1e5\n",
    "\n",
    "# Iterate while error is large and number of iterations is small enough\n",
    "while eps > 1e-4 and i < 10:\n",
    "    rho_new = min(mu * rho_new, rho_max)\n",
    "    \n",
    "    # Set CVX problem parameters\n",
    "    rho.value = rho_new\n",
    "    U.value = U_j[i]\n",
    "    V.value = V_j[i]\n",
    "    \n",
    "    # Solve optimisation problem iteration using cvx\n",
    "    prob.solve(verbose=False)\n",
    "\n",
    "    # Compute SVD of rank-constraint matrix value\n",
    "    Res = Fullmatrix.value # H_Theta_num(M, Theta, ThetaShift, X, Id, L)\n",
    "    U1, s, V1 = np.linalg.svd(Res, full_matrices=True)\n",
    "\n",
    "    U_j.append(U1[:,:N_g])\n",
    "    V_j.append(V1[:N_g,:].T)\n",
    " \n",
    "    # Update error value, and print update\n",
    "    eps = abs((obj.value - prev_value) / obj.value)\n",
    "    prev_value = obj.value\n",
    "    i = i + 1\n",
    "    print(f'Iteration {i} completed with error {obj.value:.3f} and rho={rho_new:.2f}')\n",
    "    \n",
    "# Extract solutions from optimisation procedure\n",
    "M = Mhat.value\n",
    "G = Ghat.value\n",
    "Theta = ThetaHat.value\n",
    "ThetaShift = ThetaHatShift.value\n",
    "L = Lhat.value \n",
    "\n",
    "print()\n",
    "print(f'------------------ Finished optimisation procedure with status word: {prob.status} ----------------------------')\n",
    "print(f'Found eigenvalue sequence                                  {np.array2string(np.diag(L), precision=2)}')\n",
    "# print(Theta)\n",
    "# print(ThetaShift)\n",
    "print(f\"Final nuclear norm of rank-constraint matrix               {np.linalg.norm(Res, 'nuc'):.3f}\")\n",
    "print(f'Least-square norm error ||Y - M||                          {np.linalg.norm(Y - M, 2):.3f}')\n",
    "print(f'Least-square norm error ||Y - L*G||                        {np.linalg.norm(Y - np.vander(np.diag(L), N, increasing=True).T @ G, 2):.3f}') \n",
    "# print(Res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa2dbb1c-513a-466f-93a9-129682829fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.64285396 1.26060982]\n",
      " [1.4296162  1.10827841]\n",
      " [1.20396493 1.02090597]\n",
      " [1.03867957 0.93580503]\n",
      " [0.91473971 0.85180866]\n",
      " [0.81532731 0.77212698]\n",
      " [0.73130846 0.69838918]\n",
      " [0.6580309  0.63101345]\n",
      " [0.59302736 0.56983526]\n",
      " [0.5348592  0.51445446]\n",
      " [0.48258007 0.46439668]\n",
      " [0.43549216 0.41918343]\n",
      " [0.39303482 0.3783605 ]\n",
      " [0.35473268 0.34150805]\n",
      " [0.3201702  0.30824278]\n",
      " [0.28897834 0.27821677]\n",
      " [0.26082666 0.25111515]\n",
      " [0.23541806 0.22665336]\n",
      " [0.21248493 0.20457437]\n",
      " [0.19178594 0.18464613]]\n",
      "[[-6.43521764e-05 -4.92582913e-05]\n",
      " [-1.17098802e-02  1.14811901e-02]\n",
      " [ 2.53686845e-02 -2.07833993e-02]\n",
      " [ 3.19113398e-02 -3.78954431e-02]\n",
      " [ 2.16801432e-02 -4.17189116e-02]\n",
      " [ 7.21969736e-03 -3.79241841e-02]\n",
      " [-5.81504420e-03 -3.01411691e-02]\n",
      " [-1.56094408e-02 -2.04183699e-02]\n",
      " [-2.20154601e-02 -9.92269440e-03]\n",
      " [-2.54942778e-02  6.55976927e-04]\n",
      " [-2.66595483e-02  1.08971618e-02]\n",
      " [-2.60977090e-02  2.05425837e-02]\n",
      " [-2.43083506e-02  2.94378507e-02]\n",
      " [-2.16939303e-02  3.74983232e-02]\n",
      " [-1.85680300e-02  4.46875633e-02]\n",
      " [-1.51691588e-02  5.10028180e-02]\n",
      " [-1.16748849e-02  5.64647632e-02]\n",
      " [-8.21442358e-03  6.11100395e-02]\n",
      " [-4.87919619e-03  6.49857335e-02]\n",
      " [-1.73142493e-03  6.81452748e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(np.vander(np.diag(L), N, increasing=True).T @ G)\n",
    "print(Y - np.vander(np.diag(L), N, increasing=True).T @ G)\n",
    "# print(Y - M)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
